---
title: "Final-Hamden-assessed-value-fairness"
author: "Lee-Ann Kao, Jake Todd, Ashley Yen"
date: "2025-09-18"
output: pdf_document
---

```{r}
# load libraries
library(dplyr)
library(readxl)
library(ggplot2)
library(tidyverse)
library(corrplot)
library(caret)
library(cv)
library(MASS)
library(leaflet)
```
A Hamden homeowner saw a large assessment increase shortly after purchasing and wanted to know whether the new assessed value is fair. In order to answer this question, we attempted to recreate the assessor valuation process, by using recent sales to build a pricing model, then applying it to all properties. By comparing predictions to assessments, we determined whether the assessor's values align with our estimate of value.  

# read in and join data
```{r}
# read in CT property and sales data
sale_data <- read_excel("sales_data.xlsx")
hamden_data <- read_csv("final_data.csv")
d2009 <- read_csv("Hamden2009.csv")
hamden_data <- hamden_data %>% rename(PID = PID.x)

# glance at data
head(hamden_data)
head(sale_data)
names(sale_data)
names(hamden_data)

# outer join
sale_data$Location <- paste(sale_data$`Property Number`, sale_data$`Street Name`)
merged <- left_join(hamden_data, sale_data, by = "Location")

# glance at data
head(merged)

# models for sales values
names(merged)
head(merged$Location)
```

The histogram below shows the distribution of ASR (Assessed Value/Sale Price ratio). 

# look at data relationships
```{r}
# coerce to numeric (strip $ and commas if present)
merged <- merged %>%
  mutate(
    Assessed.Total = readr::parse_number(as.character(Assessed.Total)),
    Sale.Price     = readr::parse_number(as.character(Sale.Price))
  )%>%
  filter(Sale.Price > 0)


# now compute ratios
merged <- merged %>%
  mutate(
    ASR = Assessed.Total / Sale.Price,
    Equalized_Ratio = (Assessed.Total / 0.70) / Sale.Price
  )

# histogram of ASR
head(merged$ASR)
str(merged$ASR)
summary(merged$ASR)
merged <- merged %>%
  filter(ASR < 1)

# median of data
median(merged$ASR, na.rm = TRUE)

# plot from the correct dataframe
ggplot(merged, aes(x = ASR)) +
  geom_histogram(binwidth = 0.05, fill = "steelblue", color = "white") +
  geom_vline(xintercept = 0.70, color = "red", linetype = "dashed") +
  labs(
    title = "Hamden Assessment-to-Sale Ratio (ASR)",
    x = "Assessment-to-Sale Ratio",
    y = "Count"
  )
```

The median assessed value over sale price ratio is 61%, which is lower than the statutory level of assessed value of 70% for fair market value in Connecticut. 

# prep data
```{r}
model_data <- merged %>%
  mutate(
    Sale     = readr::parse_number(as.character(Sale.Price)),
    Assessed.Total = readr::parse_number(as.character(Assessed.Total)),
    Living.Area    = as.numeric(Living.Area),
    Land.Acres     = as.numeric(Land.Acres),
    Number.of.Bedroom = as.numeric(Number.of.Bedroom),
    Number.of.Baths   = as.numeric(Number.of.Baths),
    Number.of.Half.Baths = as.numeric(Number.of.Half.Baths)
  )
```

Next, we built a predictive model using properties that actually sold in 2024. We then applied the model to properties that did not sell in 2024 in order to obtain an estimate of what those properties would have sold for in 2024. 

# model training
```{r}
for(i in 1:nrow(model_data)){
  model_data$Sale.Year[i] <- substr(model_data$Sale.Date[i], nchar(model_data$Sale.Date[i]) - 3, nchar(model_data$Sale.Date[i]))
}
model_data$Sale.Year <- as.numeric(model_data$Sale.Year)

train_data = model_data[!is.na(model_data$`Sale_2024`), ]
test_data = model_data[is.na(model_data$`Sale_2024`), ]

for(i in 1:nrow(train_data)){
  train_data$PID[i] <- str_split(train_data$link[i],"-")[[1]][2]
}
train_data$PID <- as.numeric(train_data$PID)

```
We then performed correlation analysis and stepwise regression to identify which property features are most predictive of sale price in 2024.

# look at data correlations and linear relationships
```{r}
# limit to potentially relevant variables
train_model_data <- train_data[, c('Land.Acres', 'Living.Area', 'Effective.Area', 'Total.Rooms', 'Number.of.Bedroom', 'Number.of.Baths', 'Sale_2024', 'ayb', 'eyb')]

# make correlation matrix
cor1 <- cor(train_model_data)

corrplot.mixed(cor1, lower.col = "black", upper = "ellipse", tl.col = "black", number.cex = .7, tl.pos = "lt", tl.cex=.7, sig.level = .05)

# make scatterplot matrix
library(psych)
pairs.panels(train_model_data, 
             method = "pearson",
             hist.col = "#00AFBB",
             density = TRUE
             )
```
We see that Living Area, Number of Bedrooms, Number of Baths, and Effective Year Built have the strongest correlations with Sale Price. However, there appear to be correlations between these potential predictor variables, and we therefore need to be careful of collinearity when building our model. For example, Living Area is correlated with Effective Area (0.98) and Total Rooms (0.79).

In terms of potential transformations, we see that Sale Price is right-skewed and may benefit from a log transformation.

There appear to be linear relationships between Sale Price and Land Acres, Living Area, Effective Area, Number of Bedrooms, and Number of Baths. However, there may be nonlinear relationships between Sale Price and Age at Sale and Effective Year Built.

# model selection
```{r}
# stepwise regression using AIC
set.seed(4250)
m.full <- lm(log(Sale_2024) ~ ., data = train_model_data)
m.null <- lm(log(Sale_2024) ~ 1, data = train_model_data)
m.select <- stepAIC(
  m.null,
  direction = "forward",
  trace = FALSE,
  scope = list(lower =  ~ 1, upper = formula(m.full))
)
summary(m.select)

# 10-fold cross-validation for stepwise regression
cv.select <- cv(
  selectStepAIC,
  data = train_model_data,
  seed = 4250,
  working.model = m.null,
  direction = "forward",
  scope = list(lower =  ~ 1, upper = formula(m.full))
)
summary(cv.select)
compareFolds(cv.select)

# final model
fit <- m.select
pred_sale <- predict(fit, newdata = test_data) 
test_data$Sale_2024 <- exp(pred_sale)
```
We performed stepwise regression using AIC and 10-fold cross-validation to select the best model. The final model includes Living Area, Number of Bedrooms, Number of Baths, and Effective Year Built as predictors. Based on cross-validation, there is no sign of significant overfitting, as our full-sample RMSE (0.232) is similar to the average cross-validated RMSE (0.238).

# linear model assumptions
```{r}
plot(fit)
```
The  plots above show that the linear model assumptions are reasonably satisfied. The residuals appear to be normally distributed, homoskedastic, and there is no obvious pattern in the residuals vs fitted values plot.

# plots
```{r}
# values
ggplot(test_data, aes(x = Sale_2024)) +
  geom_point(aes(y = Sale.Price), color = "blue", alpha = 0.5) +
  geom_point(aes(y = Assessed.Total / 0.70), color = "red", alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(title = "Predicted vs Actual vs Assessed Market Values",
       x = "Predicted Price (Model)",
       y = "Value",
       caption = "Blue = Actual Sale, Red = Assessor (Equalized)")

test_data$Appraised <- test_data$Assessed.Total / 0.70
test_data$residual <- test_data$Sale_2024 - test_data$Appraised
test_data$residual_normalized <- test_data$residual/test_data$Appraised
test_data$residual_normalized

ggplot(data = train_data, aes(x = `Current Year Appraisal`, y = Sale_2024)) + geom_point() + geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red")
ggplot(data = test_data, aes(x = Appraised, y = Sale_2024)) + geom_point() + geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red")
```


The plot of Predicted Price vs Assessed Value of properties shows Assessed Value in red and Predicted Price in blue. The Assessed values are typically lower than both the model-predicted and actual sale prices, suggesting that Hamden homes are being undervalued overall. 

In addition, we plotted the ASR for each property in Hamden on a map, using the property's latitude and longitude to plot. Each property is displayed as a point, with the color indicating the ASR value. Properties with high ASRs (over-assessed) are red, and those with low ASRs (under-assessed) are blue. This helps us determine whether location plays a role in fairness of value. 

# map
```{r}
# Read the object from the file
centroids <- readRDS("centroids.no.geometry.rds")

# See what type of object it is
class(centroids)

# Look at the data
head(centroids)
head(hamden_geo)

# Example with left join (keep all rows from hamden_geo)
hamden_joined <- test_data %>%
  left_join(centroids, by = c("link" = "Link"))

# Check result
hamden_joined
```

```{r}
leaflet(hamden_joined) %>%
  addTiles() %>%  # adds OpenStreetMap background
  addCircleMarkers(
    lng = ~point.x, lat = ~point.y,
    radius = 5,
    color = ~colorNumeric(palette = c("blue","white","red"), domain = hamden_joined$ASR)(ASR),
    fillOpacity = 0.7,
    popup = ~paste0(Location.y, "<br>ASR = ", round(ASR, 2))
  ) %>%
  addLegend(
    "bottomright", 
    pal = colorNumeric(c("blue","white","red"), hamden_joined$ASR),
    values = ~ASR,
    title = "ASR",
    opacity = 1
  )
```

```{r}
library(leaflet)

# 1) robust symmetric domain around 0 using 95th pct of |residual|
r <- abs(hamden_joined$residual)
m <- quantile(r, 0.95, na.rm = TRUE)   # try 0.90–0.98 if needed
dom <- c(-m, m)

# 2) palette using trimmed domain (values outside get clipped to ends)
pal <- colorNumeric(
  palette = c("blue","white","red"),
  domain  = dom,
  na.color = "transparent"
)

leaflet(hamden_joined) %>%
  addTiles() %>%
  addCircleMarkers(
    lng = ~point.x, lat = ~point.y,
    radius = 5, stroke = TRUE, color = "#333", weight = 0.5,
    fill = TRUE, fillColor = ~pal(residual), fillOpacity = 0.7,
    popup = ~paste0(Location.y, "<br>residual = ", round(residual, 2))
  ) %>%
  addLegend("bottomright", pal = pal, values = dom,  # use dom, not ~residual
            title = "residual (trimmed ±95th pct)", opacity = 1)

```

Our analysis shows that homes are generally being undervalued relative to their sales prices. From a homeowner's perspective, this is variable as it yields them a lower property tax bill. 

```{r}
library(sf); library(dplyr)

# crude polyline along CT shore of Long Island Sound (edit if you like)
shore_pts <- matrix(
  c(-73.73,41.03,  -73.37,41.03,  -73.05,41.05,  -72.60,41.15,
    -72.30,41.25,  -72.05,41.27,  -71.80,41.30), 
  ncol=2, byrow=TRUE)
shore <- st_sfc(st_linestring(shore_pts), crs = 4326)

ham <- hamden_joined %>%
  mutate(longitude = as.numeric(longitude), latitude = as.numeric(latitude)) %>%
  filter(!is.na(longitude), !is.na(latitude))
pts <- st_as_sf(ham, coords=c("longitude","latitude"), crs=4326)

# distance in meters after projecting
pts_m   <- st_transform(pts, 32618)
shore_m <- st_transform(shore, 32618)
ham$dist_to_coast_km <- as.numeric(st_distance(pts_m, shore_m)) / 1000

```

