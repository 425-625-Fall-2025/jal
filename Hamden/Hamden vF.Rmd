---
title: "Final-Hamden-assessed-value-fairness"
author: "Lee-Ann Kao, Jake Todd, Ashley Yen"
date: "2025-09-18"
output: pdf_document
---

```{r}
# load libraries
library(dplyr)
library(readxl)
library(ggplot2)
library(tidyverse)
library(corrplot)
library(MASS)
library(leaflet)
```
A Hamden homeowner saw a large assessment increase shortly after purchasing and wanted to know whether the new assessed value is fair. In order to answer this question, we attempted to recreate the assessor valuation process, by using recent sales to build a pricing model, then applying it to all properties. By comparing predictions to assessments, we determined whether the assessor's values align with our estimate of value.  

# read in and join data
```{r}
# read in CT property and sales data
sale_data <- read_excel("sales_data.xlsx")
hamden_data <- read_csv("final_data.csv")
data_2009 <- read_csv("Hamden2009.csv")
data_2009 = data_2009 %>% dplyr::select(c('pid', 'appraisedvalue'))
names(data_2009) <- c('PID', 'appraised_2009')
hamden_data <- hamden_data %>% rename(PID = PID.x)

# glance at data
head(hamden_data)
head(sale_data)
names(sale_data)
names(hamden_data)

# outer join
sale_data$Location <- paste(sale_data$`Property Number`, sale_data$`Street Name`)
merged <- left_join(hamden_data, sale_data, by = "Location")
merged <- left_join(hamden_data, data_2009, by = "PID")

# glance at data
head(merged)

# models for sales values
names(merged)
head(merged$Location)
```
The histogram below shows the distribution of ASR (Assessed Value/Sale Price ratio). 

# look at data relationships
```{r}
# coerce to numeric (strip $ and commas if present)
merged <- merged %>%
  mutate(
    Assessed.Total = readr::parse_number(as.character(Assessed.Total)),
    Sale.Price     = readr::parse_number(as.character(Sale.Price))
  )%>%
  filter(Sale.Price > 0)


# now compute ratios
merged <- merged %>%
  mutate(
    ASR = Assessed.Total / Sale.Price,
    Equalized_Ratio = (Assessed.Total / 0.70) / Sale.Price
  )

# histogram of ASR
merged$ASR
merged$Assessed.Total
head(merged$ASR)
str(merged$ASR)
summary(merged$ASR)
merged <- merged %>%
  filter(ASR < 1)

# plot from the correct dataframe
ggplot(merged, aes(x = ASR)) +
  geom_histogram(binwidth = 0.05, fill = "steelblue", color = "white") +
  geom_vline(xintercept = 0.70, color = "red", linetype = "dashed") +
  labs(
    title = "Hamden Assessment-to-Sale Ratio (ASR)",
    x = "Assessment-to-Sale Ratio",
    y = "Count"
  )
```

The histogram is approximately centered around 0.70, suggesting that on average, properties are properly assessed. This is because the statutory level of assessed value is 70% of fair market value in Connecticut. 

# prep data
```{r}
model_data <- merged %>%
  mutate(
    Sale     = readr::parse_number(as.character(Sale.Price)),
    Assessed.Total = readr::parse_number(as.character(Assessed.Total)),
    Living.Area    = as.numeric(Living.Area),
    Land.Acres     = as.numeric(Land.Acres),
    Number.of.Bedroom = as.numeric(Number.of.Bedroom),
    Number.of.Baths   = as.numeric(Number.of.Baths),
    Number.of.Half.Baths = as.numeric(Number.of.Half.Baths)
  )
```

Next, we built a predictive model using properties that actually sold in 2024. We then applied the model to properties that did not sell in 2024 in order to obtain an estimate of what those properties would have sold for in 2024. 

# model training
```{r}
for(i in 1:nrow(model_data)){
  model_data$Sale.Year[i] <- substr(model_data$Sale.Date[i], nchar(model_data$Sale.Date[i]) - 3, nchar(model_data$Sale.Date[i]))
}
model_data$Sale.Year <- as.numeric(model_data$Sale.Year)

train_data = model_data[!is.na(model_data$`Sale_2024`), ]
test_data = model_data[is.na(model_data$`Sale_2024`), ]

for(i in 1:nrow(train_data)){
  train_data$PID[i] <- str_split(train_data$link[i],"-")[[1]][2]
}
train_data$PID <- as.numeric(train_data$PID)

```
We then performed correlation analysis and stepwise regression to identify which property features are most predictive of sale price in 2024.

# model selection
```{r}
# make correlation matrix
cor1 <- cor(train_data[, c('Sale_2024', 'Pre.Yr.Assessed.Total', 'Land.Acres', 'Living.Area', 'Effective.Area', 'Total.Rooms', 'Number.of.Bedroom', 'Number.of.Baths', 'Number.of.Half.Baths', 'ayb', 'eyb', 'appraised_2009')], use = "pairwise.complete.obs")

corrplot.mixed(cor1, lower.col = "black", upper = "ellipse", tl.col = "black", number.cex = .7, tl.pos = "lt", tl.cex=.7, sig.level = .05)

# limit to potentially relevant variables
train_model_data <- train_data[, c('Land.Acres', 'Living.Area', 'Effective.Area', 'Total.Rooms', 'Number.of.Bedroom', 'Number.of.Baths', 'Sale_2024', 'ayb', 'eyb', 'appraised_2009')]
train_model_data = train_model_data[!is.na(train_model_data$appraised_2009),]

# perform best subsets regression
full_model <- lm(log(Sale_2024) ~ ., data = train_model_data)
null_model <- lm(log(Sale_2024) ~ 1, data = train_model_data)
n <- nrow(train_model_data)

# stepwise regression using BIC
stepwise_bic_model <- stepAIC(null_model,
                              direction = "both",
                              scope = list(upper = full_model, lower = null_model),
                              k = log(n))
summary(stepwise_bic_model)

# stepwise regression AIC
stepwise_aic_model <- stepAIC(full_model, direction = "both", trace = FALSE)
summary(stepwise_aic_model)

# final model
fit <- stepwise_aic_model
pred_sale <- predict(fit, newdata = test_data) 
test_data$Sale_2024 <- exp(pred_sale)
```

The correlation plot includes the following variables: Sale Price, Previous Year Assessed Total, Land Acres, Living Area, Effective Area, Total Rooms, Number of Bedroom, Number of Baths, Number of Half Baths, ayb, eyb, and appraised 2009 value. All pairs of variables except Number of Baths and Number of Half Baths had positive or neutral correlations. Previous year assess total, appraised value in 2009, living area, and effective area had the highest correlations with Sale Price, while ayb and number of half baths had the lowest correlation with sale price.

Next, we used BIC-based stepwise selection and AIC-based stepwise selection to decide which predictors to use in our model. 

BIC-based stepwise selection chose a model with 3 predictors: Appraised 2009 value, land acres, and number of bedrooms, yielding an  Adjusted R^2 of about 0.7549. While all coefficients are significant, land acres has a negative coefficient which does not make sense.

AIC-based stepwise selection chose a model with 4 predictors: Land acres, number of bedrooms, number of baths, and appraised value in 2009. This model resulted in an adjusted R^2 value of 0.7565. Like the BIC model, land acres has a negative coefficient which does not make sense. Furthermore, all predictors except number of baths is significant.

We chose the AIC-based model as our final model, as it had a slightly higher Adjusted R^2 and included more predictors.

Finally, we compared each property's assessed value with the predicted value from our model. 

# plot
```{r}
# residuals and assumptions
qqnorm(scale(resid(fit)))
abline(0,1)

# values
ggplot(test_data, aes(x = Sale_2024)) +
  geom_point(aes(y = Sale.Price), color = "blue", alpha = 0.5) +
  geom_point(aes(y = Assessed.Total / 0.70), color = "red", alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(title = "Predicted vs Actual vs Assessed Market Values",
       x = "Predicted Price (Model)",
       y = "Value",
       caption = "Blue = Actual Sale, Red = Assessor (Equalized)")

test_data$Appraised <- test_data$Assessed.Total / 0.70
test_data$residual <- test_data$Sale_2024 - test_data$Appraised
test_data$residual_normalized <- test_data$residual/test_data$Appraised
test_data$residual_normalized

ggplot(data = train_data, aes(x = `Current Year Appraisal`, y = Sale_2024)) + geom_point() + geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red")
ggplot(data = test_data, aes(x = Appraised, y = Sale_2024)) + geom_point() + geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red")
```


The plot of Predicted Price vs Assessed Value of properties shows Assessed Value in red and Predicted Price in blue. The Assessed values are typically lower than both the model-predicted and actual sale prices, suggesting that Hamden homes are being undervalued overall. 

In addition, we plotted the ASR for each property in Hamden on a map, using the property's latitude and longitude to plot. Each property is displayed as a point, with the color indicating the ASR value. Properties with high ASRs (over-assessed) are red, and those with low ASRs (under-assessed) are blue. This helps us determine whether location plays a role in fairness of value. 

# map
```{r}
# Read the object from the file
centroids <- readRDS("centroids.no.geometry.rds")

# See what type of object it is
class(centroids)

# Look at the data
head(centroids)
head(hamden_geo)

# Example with left join (keep all rows from hamden_geo)
hamden_joined <- test_data %>%
  left_join(centroids, by = c("link" = "Link"))

# Check result
hamden_joined
```

```{r}
leaflet(hamden_joined) %>%
  addTiles() %>%  # adds OpenStreetMap background
  addCircleMarkers(
    lng = ~point.x, lat = ~point.y,
    radius = 5,
    color = ~colorNumeric(palette = c("blue","white","red"), domain = hamden_joined$ASR)(ASR),
    fillOpacity = 0.7,
    popup = ~paste0(Location.y, "<br>ASR = ", round(ASR, 2))
  ) %>%
  addLegend(
    "bottomright", 
    pal = colorNumeric(c("blue","white","red"), hamden_joined$ASR),
    values = ~ASR,
    title = "ASR",
    opacity = 1
  )
```

```{r}
library(leaflet)

# 1) robust symmetric domain around 0 using 95th pct of |residual|
r <- abs(hamden_joined$residual)
m <- quantile(r, 0.95, na.rm = TRUE)   # try 0.90â€“0.98 if needed
dom <- c(-m, m)

# 2) palette using trimmed domain (values outside get clipped to ends)
pal <- colorNumeric(
  palette = c("blue","white","red"),
  domain  = dom,
  na.color = "transparent"
)

leaflet(hamden_joined) %>%
  addTiles() %>%
  addCircleMarkers(
    lng = ~point.x, lat = ~point.y,
    radius = 5, stroke = TRUE, color = "#333", weight = 0.5,
    fill = TRUE, fillColor = ~pal(residual), fillOpacity = 0.7,
    popup = ~paste0(Location.y, "<br>residual = ", round(residual, 2))
  ) %>%
  addLegend("bottomright", pal = pal, values = dom,  # use dom, not ~residual
            title = "residual (trimmed Â±95th pct)", opacity = 1)

```

Our analysis shows that homes are generally being undervalued relative to their sales prices. From a homeowner's perspective, this is variable as it yields them a lower property tax bill. 

```{r}
library(sf); library(dplyr)

# crude polyline along CT shore of Long Island Sound (edit if you like)
shore_pts <- matrix(
  c(-73.73,41.03,  -73.37,41.03,  -73.05,41.05,  -72.60,41.15,
    -72.30,41.25,  -72.05,41.27,  -71.80,41.30), 
  ncol=2, byrow=TRUE)
shore <- st_sfc(st_linestring(shore_pts), crs = 4326)

ham <- hamden_joined %>%
  mutate(longitude = as.numeric(longitude), latitude = as.numeric(latitude)) %>%
  filter(!is.na(longitude), !is.na(latitude))
pts <- st_as_sf(ham, coords=c("longitude","latitude"), crs=4326)

# distance in meters after projecting
pts_m   <- st_transform(pts, 32618)
shore_m <- st_transform(shore, 32618)
ham$dist_to_coast_km <- as.numeric(st_distance(pts_m, shore_m)) / 1000

```

